{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03d4fe54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/user2/2021_patent\n",
      "finding matches\n",
      "100000: 532\n",
      "200000: 1168\n",
      "found 1340 groups\n",
      "merging firms\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "\n",
    "import py_stringmatching\n",
    "from math import floor\n",
    "\n",
    "from py_stringmatching import JaroWinkler\n",
    "jw = JaroWinkler()\n",
    "\n",
    "\n",
    "# Function to calculate the\n",
    "# Jaro Similarity of two strings\n",
    "\n",
    "    \n",
    "# name matching using locality-sensitive hashing (simhash)\n",
    "# these are mostly idempotent\n",
    "\n",
    "jw = JaroWinkler()\n",
    "ja = py_stringmatching.similarity_measure.jaccard.Jaccard()\n",
    "co = py_stringmatching.similarity_measure.cosine.Cosine()\n",
    "from py_stringmatching import SoftTfIdf\n",
    "me = py_stringmatching.similarity_measure.monge_elkan.MongeElkan()\n",
    "from py_stringmatching import Levenshtein\n",
    "leven = Levenshtein()\n",
    "from py_stringmatching import TfIdf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from itertools import chain, repeat\n",
    "from collections import defaultdict\n",
    "from math import ceil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from editdistance import eval as levenshtein\n",
    "\n",
    "from standardize import standardize_weak, standardize_strong\n",
    "from tables import read_csv\n",
    "from simhash import shingle, Cluster\n",
    "\n",
    "# firm name sources - tag: (table, id_col, name_col)\n",
    "colmap = {\n",
    "    'apply': ('apply_apply', 'appnum', 'appname'),\n",
    "    'grant': ('grant_grant', 'patnum', 'owner'),\n",
    "    'assignor': ('assign_use', 'assignid', 'assignor'),\n",
    "    'assignee': ('assign_use', 'assignid', 'assignee'),\n",
    "    'compustat': ('compustat', 'compid', 'name'),\n",
    "}\n",
    "\n",
    "# find all unique names\n",
    "def generate_names(output, columns):\n",
    "    print('generating names')\n",
    "\n",
    "    sdict = {}\n",
    "    for tag, (table, id_col, name_col) in columns.items():\n",
    "        src = read_csv(f'{output}/{table}.csv', usecols=[id_col, name_col]).dropna()\n",
    "        src['name'] = src[name_col].apply(standardize_weak)\n",
    "        sdict[tag] = src\n",
    "\n",
    "    names = pd.concat([src['name'] for src in sdict.values()], axis=0).drop_duplicates()\n",
    "    names = names[names.str.len()>0].reset_index(drop=True)\n",
    "    names = names.rename('name').rename_axis('id').reset_index()\n",
    "    names.to_csv(f'{output}/name.csv', index=False)\n",
    "\n",
    "    for tag, (table, id_col, name_col) in columns.items():\n",
    "        src = pd.merge(sdict[tag], names, how='left', on='name')\n",
    "        src[[id_col, 'id']].to_csv(f'{output}/{tag}_match.csv', index=False)\n",
    "\n",
    "    print(f'found {len(names)} names')\n",
    "\n",
    "# k = 8, thresh = 4 works well\n",
    "def filter_pairs(output, nshingle=2, k=8, thresh=4):\n",
    "    print('filtering pairs')\n",
    "\n",
    "    c = Cluster(k=k, thresh=thresh)\n",
    "    name_dict = {}\n",
    "\n",
    "    names = read_csv(f'{output}/name.csv', usecols=['id', 'name'])\n",
    "    for i, id, name in names.itertuples():\n",
    "        words = name.split()\n",
    "        shings = list(shingle(name, nshingle))\n",
    "\n",
    "        features = shings + words\n",
    "        weights = list(np.linspace(1.0, 0.0, len(shings))) + list(np.linspace(1.0, 0.0, len(words)))\n",
    "\n",
    "        c.add(features, weights=weights, label=id)\n",
    "        name_dict[id] = name\n",
    "\n",
    "        if i > 0 and i % 100_000 == 0:\n",
    "            print(f'{i}: {len(c.unions)}')\n",
    "\n",
    "    pairs = pd.DataFrame([(i1, i2, name_dict[i1], name_dict[i2]) for i1, i2 in c.unions], columns=['id1', 'id2', 'name1', 'name2'])\n",
    "    pairs.to_csv(f'{output}/pair.csv', index=False)\n",
    "\n",
    "    print('Found %i pairs' % len(pairs))\n",
    "\n",
    "# compute distances on owners in same cluster\n",
    "def find_groups(output, thresh=0.80):\n",
    "    print('finding matches')\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    def dmetr(name1, name2):\n",
    "        max_len = max(len(name1), len(name2))\n",
    "        max_dist = int(ceil(max_len*(1.0-thresh)))\n",
    "        set_name1 = name1.split()\n",
    "        set_name2 = name2.split()\n",
    "        ldist = ja.get_sim_score(set_name1, set_name2)\n",
    "        #ldist = co.get_sim_score(set_name1, set_name2)\n",
    "        #sf = SoftTfIdf([set_name1, set_name2])\n",
    "        #ldist = sf.get_raw_score(set_name1, set_name2)\n",
    "        #ldist = jw.get_sim_score(name1, name2)\n",
    "        #ldist = me.get_raw_score(set_name1, set_name2)\n",
    "        #ldist = leven.get_sim_score(name1, name2)\n",
    "        #tf = TfIdf([set_name1, set_name2])\n",
    "        #ldist = tf.get_sim_score(set_name1, set_name2)\n",
    "        return ldist if (ldist != -1 and max_len != 0) else 0.0\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    close = []\n",
    "    name_std = {}\n",
    "\n",
    "    pairs = read_csv(f'{output}/pair0.csv', usecols=['id1', 'id2', 'name1', 'name2'])\n",
    "    for i, id1, id2, name1, name2 in pairs.itertuples():\n",
    "        if id1 not in name_std:\n",
    "            name_std[id1] = standardize_strong(name1)\n",
    "        if id2 not in name_std:\n",
    "            name_std[id2] = standardize_strong(name2)\n",
    "        \n",
    "        #name을 공백을 기준으로 분리후 집합으로 선언합니다.\n",
    "        #n1std = set(name_std[id1].split())\n",
    "        #n2std = set(name_std[id2].split())\n",
    "        \n",
    "        #생성된 집합끼리 차집합 연산을 통해 공통된 원소를 삭제하고 다시 리스트로 변환합니다.\n",
    "        #n1std1 = list(n1std - n2std)\n",
    "        #n2std2 = list(n2std - n1std)\n",
    "        \n",
    "        #공통 원소가 제거된 원소를 다시 문자열로 복원시킵니다.\n",
    "        #n1std = \" \".join(n1std1)\n",
    "        #n2std = \" \".join(n2std2)\n",
    "        n1std = name_std[id1]\n",
    "        n2std = name_std[id2]\n",
    "        \n",
    "        if dmetr(n1std, n2std) > thresh:\n",
    "            close.append((id1, id2))\n",
    "\n",
    "        if i > 0 and i % 100_000 == 0:\n",
    "            print(f'{i}: {len(close)}')\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(close)\n",
    "    comps = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "\n",
    "    match = pd.DataFrame(chain(*[zip(repeat(fid), ids) for fid, ids in enumerate(comps)]), columns=['firm_num', 'id'])\n",
    "    match.to_csv(f'{output}/match_JC_pair0.csv', index=False)\n",
    "\n",
    "    print(f'found {len(comps)} groups')\n",
    "\n",
    "\n",
    "# must be less than 1000000 components\n",
    "def merge_firms(output, columns, base=1000000):\n",
    "    print('merging firms')\n",
    "\n",
    "    names = read_csv(f'{output}/name.csv')\n",
    "    match = read_csv(f'{output}/match_JC_pair0.csv')\n",
    "    firms = pd.merge(names, match, how='left', on='id')\n",
    "    firms['firm_num'] = firms['firm_num'].fillna(firms['id']+base)\n",
    "    firms[['firm_num', 'id']].to_csv(f'{output}/firm_JC_pair0.csv', index=False)\n",
    "\n",
    "    for tag, (table, id_col, name_col) in columns.items():\n",
    "        src = read_csv(f'{output}/{tag}_match.csv')\n",
    "        src = pd.merge(src, firms, on='id')\n",
    "        src[[id_col, 'firm_num']].to_csv(f'{output}/{tag}_firm_JC_pair0.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    import easydict\n",
    " \n",
    "    args = easydict.EasyDict({\n",
    "        \"sources\": \"\",\n",
    "        \"output\": \"tables\",\n",
    "    })\n",
    " \n",
    "\n",
    "    import argparse\n",
    "\n",
    "    # parse input arguments\n",
    "    #parser = argparse.ArgumentParser(description='Create firm name clusters.')\n",
    "    #parser.add_argument('sources', nargs='*', type=str, help='data sources to use')\n",
    "    #parser.add_argument('--output', type=str, default='tables', help='directory to operate on')\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    sources0 = ['apply', 'grant', 'assignee', 'assignor']\n",
    "    sources = args.sources if len(args.sources) > 0 else sources0\n",
    "    columns = {s: colmap[s] for s in sources}\n",
    "\n",
    "    # go through steps\n",
    "    #generate_names(args.output, columns)\n",
    "    #filter_pairs(args.output)\n",
    "    find_groups(args.output)\n",
    "    merge_firms(args.output, columns)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1e190a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me = py_stringmatching.similarity_measure.monge_elkan.MongeElkan()\n",
    "me.get_raw_score(['a', 'b', 'a'], ['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cd04efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SoftTfIdf = py_stringmatching.similarity_measure.soft_tfidf.SoftTfIdf()\n",
    "from py_stringmatching import SoftTfIdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a672a39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from py_stringmatching import Levenshtein\n",
    "leven = Levenshtein()\n",
    "leven.get_sim_score(\"cook\", \"book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144403a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name1 = \"the university of male\"\n",
    "name2 = \"of the a university of madrid holdings\"\n",
    "#x.split()\n",
    "#jw.get_sim_score(x, y)\n",
    "#standardize_strong(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793cf9b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_sim_score() missing 2 required positional arguments: 'bag1' and 'bag2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2619/108060943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfIdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mset_name1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_name2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sim_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: get_sim_score() missing 2 required positional arguments: 'bag1' and 'bag2'"
     ]
    }
   ],
   "source": [
    "def distinguish_function(x, y):\n",
    "    set_x = set(x.split())\n",
    "    set_y = set(y.split())\n",
    "    new_x = list(set_x - set_y)\n",
    "    new_y = list(set_y- set_x)\n",
    "    x_string = \" \".join(new_x)\n",
    "    y_string = \" \".join(new_y)\n",
    "    jw.get_sim_score(x_string, y_string)\n",
    "from py_stringmatching import TfIdf\n",
    "set_name1 = name1.split()\n",
    "set_name2 = name2.split()\n",
    "\n",
    "tf = TfIdf([set_name1, set_name2])\n",
    "tf.get_sim_score(set_name1, set_name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9fbf43ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/user2/2021_patent\r\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfIdf([['a', 'b', 'a'], ['a', 'c'], ['a']])\n",
    "tfidf.get_raw_score(['a', 'b', 'a'], ['b', 'c'])\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7837f898",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = pd.read_csv(\"/mnt/user2/R/geocode.csv\", dtype={\"State Code (FIPS)\" : str, \"County Code (FIPS)\" : str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "48db12a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo[\"city_name\"] = city_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e19ea0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Autauga',\n",
       " 'Baldwin',\n",
       " 'Barbour',\n",
       " 'Bibb',\n",
       " 'Blount',\n",
       " 'Bullock',\n",
       " 'Butler',\n",
       " 'Calhoun',\n",
       " 'Chambers',\n",
       " 'Cherokee',\n",
       " 'Chilton',\n",
       " 'Choctaw',\n",
       " 'Clarke',\n",
       " 'Clay',\n",
       " 'Cleburne',\n",
       " 'Coffee',\n",
       " 'Colbert',\n",
       " 'Conecuh',\n",
       " 'Coosa',\n",
       " 'Covington',\n",
       " 'Crenshaw',\n",
       " 'Cullman',\n",
       " 'Dale',\n",
       " 'Dallas',\n",
       " 'DeKalb',\n",
       " 'Elmore',\n",
       " 'Escambia',\n",
       " 'Etowah',\n",
       " 'Fayette',\n",
       " 'Franklin',\n",
       " 'Geneva',\n",
       " 'Greene',\n",
       " 'Hale',\n",
       " 'Henry',\n",
       " 'Houston',\n",
       " 'Jackson',\n",
       " 'Jefferson',\n",
       " 'Lamar',\n",
       " 'Lauderdale',\n",
       " 'Lawrence',\n",
       " 'Lee',\n",
       " 'Limestone',\n",
       " 'Lowndes',\n",
       " 'Macon',\n",
       " 'Madison',\n",
       " 'Marengo',\n",
       " 'Marion',\n",
       " 'Marshall',\n",
       " 'Mobile',\n",
       " 'Monroe',\n",
       " 'Montgomery',\n",
       " 'Morgan',\n",
       " 'Perry',\n",
       " 'Pickens',\n",
       " 'Pike',\n",
       " 'Randolph',\n",
       " 'Russell',\n",
       " 'St. Clair',\n",
       " 'Shelby',\n",
       " 'Sumter',\n",
       " 'Talladega',\n",
       " 'Tallapoosa',\n",
       " 'Tuscaloosa',\n",
       " 'Walker',\n",
       " 'Washington',\n",
       " 'Wilcox',\n",
       " 'Winston',\n",
       " 'Aleutians East',\n",
       " 'Aleutians West Census',\n",
       " 'Anchorage',\n",
       " 'Bethel Census',\n",
       " 'Bristol Bay',\n",
       " 'Chugach Census',\n",
       " 'Copper River Census',\n",
       " 'Denali',\n",
       " 'Dillingham Census',\n",
       " 'Fairbanks North Star',\n",
       " 'Haines',\n",
       " 'Hoonah-Angoon Census',\n",
       " 'Juneau City and',\n",
       " 'Kenai Peninsula',\n",
       " 'Ketchikan Gateway',\n",
       " 'Kodiak Island',\n",
       " 'Kusilvak Census',\n",
       " 'Lake and Peninsula',\n",
       " 'Matanuska-Susitna',\n",
       " 'Nome Census',\n",
       " 'North Slope',\n",
       " 'Northwest Arctic',\n",
       " 'Petersburg',\n",
       " 'Prince of Wales-Hyder Census',\n",
       " 'Sitka City and',\n",
       " 'Skagway',\n",
       " 'Southeast Fairbanks Census',\n",
       " 'Wrangell City and',\n",
       " 'Yakutat City and',\n",
       " 'Yukon-Koyukuk Census',\n",
       " 'Apache',\n",
       " 'Cochise',\n",
       " 'Coconino',\n",
       " 'Gila',\n",
       " 'Graham',\n",
       " 'Greenlee',\n",
       " 'La Paz',\n",
       " 'Maricopa',\n",
       " 'Mohave',\n",
       " 'Navajo',\n",
       " 'Pima',\n",
       " 'Pinal',\n",
       " 'Santa Cruz',\n",
       " 'Yavapai',\n",
       " 'Yuma',\n",
       " 'Arkansas',\n",
       " 'Ashley',\n",
       " 'Baxter',\n",
       " 'Benton',\n",
       " 'Boone',\n",
       " 'Bradley',\n",
       " 'Calhoun',\n",
       " 'Carroll',\n",
       " 'Chicot',\n",
       " 'Clark',\n",
       " 'Clay',\n",
       " 'Cleburne',\n",
       " 'Cleveland',\n",
       " 'Columbia',\n",
       " 'Conway',\n",
       " 'Craighead',\n",
       " 'Crawford',\n",
       " 'Crittenden',\n",
       " 'Cross',\n",
       " 'Dallas',\n",
       " 'Desha',\n",
       " 'Drew',\n",
       " 'Faulkner',\n",
       " 'Franklin',\n",
       " 'Fulton',\n",
       " 'Garland',\n",
       " 'Grant',\n",
       " 'Greene',\n",
       " 'Hempstead',\n",
       " 'Hot Spring',\n",
       " 'Howard',\n",
       " 'Independence',\n",
       " 'Izard',\n",
       " 'Jackson',\n",
       " 'Jefferson',\n",
       " 'Johnson',\n",
       " 'Lafayette',\n",
       " 'Lawrence',\n",
       " 'Lee',\n",
       " 'Lincoln',\n",
       " 'Little River',\n",
       " 'Logan',\n",
       " 'Lonoke',\n",
       " 'Madison',\n",
       " 'Marion',\n",
       " 'Miller',\n",
       " 'Mississippi',\n",
       " 'Monroe',\n",
       " 'Montgomery',\n",
       " 'Nevada',\n",
       " 'Newton',\n",
       " 'Ouachita',\n",
       " 'Perry',\n",
       " 'Phillips',\n",
       " 'Pike',\n",
       " 'Poinsett',\n",
       " 'Polk',\n",
       " 'Pope',\n",
       " 'Prairie',\n",
       " 'Pulaski',\n",
       " 'Randolph',\n",
       " 'St. Francis',\n",
       " 'Saline',\n",
       " 'Scott',\n",
       " 'Searcy',\n",
       " 'Sebastian',\n",
       " 'Sevier',\n",
       " 'Sharp',\n",
       " 'Stone',\n",
       " 'Union',\n",
       " 'Van Buren',\n",
       " 'Washington',\n",
       " 'White',\n",
       " 'Woodruff',\n",
       " 'Yell',\n",
       " 'Alameda',\n",
       " 'Alpine',\n",
       " 'Amador',\n",
       " 'Butte',\n",
       " 'Calaveras',\n",
       " 'Colusa',\n",
       " 'Contra Costa',\n",
       " 'Del Norte',\n",
       " 'El Dorado',\n",
       " 'Fresno',\n",
       " 'Glenn',\n",
       " 'Humboldt',\n",
       " 'Imperial',\n",
       " 'Inyo',\n",
       " 'Kern',\n",
       " 'Kings',\n",
       " 'Lake',\n",
       " 'Lassen',\n",
       " 'Los Angeles',\n",
       " 'Madera',\n",
       " 'Marin',\n",
       " 'Mariposa',\n",
       " 'Mendocino',\n",
       " 'Merced',\n",
       " 'Modoc',\n",
       " 'Mono',\n",
       " 'Monterey',\n",
       " 'Napa',\n",
       " 'Nevada',\n",
       " 'Orange',\n",
       " 'Placer',\n",
       " 'Plumas',\n",
       " 'Riverside',\n",
       " 'Sacramento',\n",
       " 'San Benito',\n",
       " 'San Bernardino',\n",
       " 'San Diego',\n",
       " 'San Francisco',\n",
       " 'San Joaquin',\n",
       " 'San Luis Obispo',\n",
       " 'San Mateo',\n",
       " 'Santa Barbara',\n",
       " 'Santa Clara',\n",
       " 'Santa Cruz',\n",
       " 'Shasta',\n",
       " 'Sierra',\n",
       " 'Siskiyou',\n",
       " 'Solano',\n",
       " 'Sonoma',\n",
       " 'Stanislaus',\n",
       " 'Sutter',\n",
       " 'Tehama',\n",
       " 'Trinity',\n",
       " 'Tulare',\n",
       " 'Tuolumne',\n",
       " 'Ventura',\n",
       " 'Yolo',\n",
       " 'Yuba',\n",
       " 'Adams',\n",
       " 'Alamosa',\n",
       " 'Arapahoe',\n",
       " 'Archuleta',\n",
       " 'Baca',\n",
       " 'Bent',\n",
       " 'Boulder',\n",
       " 'Broomfield',\n",
       " 'Chaffee',\n",
       " 'Cheyenne',\n",
       " 'Clear Creek',\n",
       " 'Conejos',\n",
       " 'Costilla',\n",
       " 'Crowley',\n",
       " 'Custer',\n",
       " 'Delta',\n",
       " 'Denver',\n",
       " 'Dolores',\n",
       " 'Douglas',\n",
       " 'Eagle',\n",
       " 'Elbert',\n",
       " 'El Paso',\n",
       " 'Fremont',\n",
       " 'Garfield',\n",
       " 'Gilpin',\n",
       " 'Grand',\n",
       " 'Gunnison',\n",
       " 'Hinsdale',\n",
       " 'Huerfano',\n",
       " 'Jackson',\n",
       " 'Jefferson',\n",
       " 'Kiowa',\n",
       " 'Kit Carson',\n",
       " 'Lake',\n",
       " 'La Plata',\n",
       " 'Larimer',\n",
       " 'Las Animas',\n",
       " 'Lincoln',\n",
       " 'Logan',\n",
       " 'Mesa',\n",
       " 'Mineral',\n",
       " 'Moffat',\n",
       " 'Montezuma',\n",
       " 'Montrose',\n",
       " 'Morgan',\n",
       " 'Otero',\n",
       " 'Ouray',\n",
       " 'Park',\n",
       " 'Phillips',\n",
       " 'Pitkin',\n",
       " 'Prowers',\n",
       " 'Pueblo',\n",
       " 'Rio Blanco',\n",
       " 'Rio Grande',\n",
       " 'Routt',\n",
       " 'Saguache',\n",
       " 'San Juan',\n",
       " 'San Miguel',\n",
       " 'Sedgwick',\n",
       " 'Summit',\n",
       " 'Teller',\n",
       " 'Washington',\n",
       " 'Weld',\n",
       " 'Yuma',\n",
       " 'Fairfield',\n",
       " 'Hartford',\n",
       " 'Litchfield',\n",
       " 'Middlesex',\n",
       " 'New Haven',\n",
       " 'New London',\n",
       " 'Tolland',\n",
       " 'Windham',\n",
       " 'Bethel',\n",
       " 'Bridgeport',\n",
       " 'Brookfield',\n",
       " 'Danbury',\n",
       " 'Darien',\n",
       " 'Easton',\n",
       " 'Fairfield',\n",
       " 'Greenwich',\n",
       " 'Monroe',\n",
       " 'New Canaan',\n",
       " 'New Fairfield',\n",
       " 'Newtown',\n",
       " 'Norwalk',\n",
       " 'Redding',\n",
       " 'Ridgefield',\n",
       " 'Shelton',\n",
       " 'Sherman',\n",
       " 'Stamford',\n",
       " 'Stratford',\n",
       " 'Trumbull',\n",
       " 'Weston',\n",
       " 'Westport',\n",
       " 'Wilton',\n",
       " 'Avon',\n",
       " 'Berlin',\n",
       " 'Bloomfield',\n",
       " 'Bristol',\n",
       " 'Burlington',\n",
       " 'Canton',\n",
       " 'East Granby',\n",
       " 'East Hartford',\n",
       " 'East Windsor',\n",
       " 'Enfield',\n",
       " 'Farmington',\n",
       " 'Glastonbury',\n",
       " 'Granby',\n",
       " 'Hartford',\n",
       " 'Hartland',\n",
       " 'Manchester',\n",
       " 'Marlborough',\n",
       " 'New Britain',\n",
       " 'Newington',\n",
       " 'Plainville',\n",
       " 'Rocky Hill',\n",
       " 'Simsbury',\n",
       " 'Southington',\n",
       " 'South Windsor',\n",
       " 'Suffield',\n",
       " 'West Hartford',\n",
       " 'Wethersfield',\n",
       " 'Windsor',\n",
       " 'Windsor Locks',\n",
       " 'Barkhamsted',\n",
       " 'Bethlehem',\n",
       " 'Bridgewater',\n",
       " 'Canaan',\n",
       " 'Colebrook',\n",
       " 'Cornwall',\n",
       " 'Goshen',\n",
       " 'Harwinton',\n",
       " 'Kent',\n",
       " 'Litchfield',\n",
       " 'Morris',\n",
       " 'New Hartford',\n",
       " 'New Milford',\n",
       " 'Norfolk',\n",
       " 'North Canaan',\n",
       " 'Plymouth',\n",
       " 'Roxbury',\n",
       " 'Salisbury',\n",
       " 'Sharon',\n",
       " 'Thomaston',\n",
       " 'Torrington',\n",
       " 'Warren',\n",
       " 'Washington',\n",
       " 'Watertown',\n",
       " 'Winchester',\n",
       " 'Woodbury',\n",
       " 'Chester',\n",
       " 'Clinton',\n",
       " 'Cromwell',\n",
       " 'Deep River',\n",
       " 'Durham',\n",
       " 'East Haddam',\n",
       " 'East Hampton',\n",
       " 'Essex',\n",
       " 'Haddam',\n",
       " 'Killingworth',\n",
       " 'Middlefield',\n",
       " 'Middletown',\n",
       " 'Old Saybrook',\n",
       " 'Portland',\n",
       " 'Westbrook',\n",
       " 'Ansonia',\n",
       " 'Beacon Falls',\n",
       " 'Bethany',\n",
       " 'Branford',\n",
       " 'Cheshire',\n",
       " 'Derby',\n",
       " 'East Haven',\n",
       " 'Guilford',\n",
       " 'Hamden',\n",
       " 'Madison',\n",
       " 'Meriden',\n",
       " 'Middlebury',\n",
       " 'Milford',\n",
       " 'Naugatuck',\n",
       " 'New Haven',\n",
       " 'North Branford',\n",
       " 'North Haven',\n",
       " 'Orange',\n",
       " 'Oxford',\n",
       " 'Prospect',\n",
       " 'Seymour',\n",
       " 'Southbury',\n",
       " 'Wallingford',\n",
       " 'Waterbury',\n",
       " 'West Haven',\n",
       " 'Wolcott',\n",
       " 'Woodbridge',\n",
       " 'Bozrah',\n",
       " 'Colchester',\n",
       " 'East Lyme',\n",
       " 'Franklin',\n",
       " 'Griswold',\n",
       " 'Groton',\n",
       " 'Lebanon',\n",
       " 'Ledyard',\n",
       " 'Lisbon',\n",
       " 'Lyme',\n",
       " 'Montville',\n",
       " 'New London',\n",
       " 'North Stonington',\n",
       " 'Norwich',\n",
       " 'Old Lyme',\n",
       " 'Preston',\n",
       " 'Salem',\n",
       " 'Sprague',\n",
       " 'Stonington',\n",
       " 'Voluntown',\n",
       " 'Waterford',\n",
       " 'Andover',\n",
       " 'Bolton',\n",
       " 'Columbia',\n",
       " 'Coventry',\n",
       " 'Ellington',\n",
       " 'Hebron',\n",
       " 'Mansfield',\n",
       " 'Somers',\n",
       " 'Stafford',\n",
       " 'Tolland',\n",
       " 'Union',\n",
       " 'Vernon',\n",
       " 'Willington',\n",
       " 'Ashford',\n",
       " 'Brooklyn',\n",
       " 'Canterbury',\n",
       " 'Chaplin',\n",
       " 'Eastford',\n",
       " 'Hampton',\n",
       " 'Killingly',\n",
       " 'Plainfield',\n",
       " 'Pomfret',\n",
       " 'Putnam',\n",
       " 'Scotland',\n",
       " 'Sterling',\n",
       " 'Thompson',\n",
       " 'Windham',\n",
       " 'Woodstock',\n",
       " 'Kent',\n",
       " 'New Castle',\n",
       " 'Sussex',\n",
       " 'District of',\n",
       " 'Alachua',\n",
       " 'Baker',\n",
       " 'Bay',\n",
       " 'Bradford',\n",
       " 'Brevard',\n",
       " 'Broward',\n",
       " 'Calhoun',\n",
       " 'Charlotte',\n",
       " 'Citrus',\n",
       " 'Clay',\n",
       " 'Collier',\n",
       " 'Columbia',\n",
       " 'DeSoto',\n",
       " 'Dixie',\n",
       " 'Duval',\n",
       " 'Escambia',\n",
       " 'Flagler',\n",
       " 'Franklin',\n",
       " 'Gadsden',\n",
       " 'Gilchrist',\n",
       " 'Glades',\n",
       " 'Gulf',\n",
       " 'Hamilton',\n",
       " 'Hardee',\n",
       " 'Hendry',\n",
       " 'Hernando',\n",
       " 'Highlands',\n",
       " 'Hillsborough',\n",
       " 'Holmes',\n",
       " 'Indian River',\n",
       " 'Jackson',\n",
       " 'Jefferson',\n",
       " 'Lafayette',\n",
       " 'Lake',\n",
       " 'Lee',\n",
       " 'Leon',\n",
       " 'Levy',\n",
       " 'Liberty',\n",
       " 'Madison',\n",
       " 'Manatee',\n",
       " 'Marion',\n",
       " 'Martin',\n",
       " 'Miami-Dade',\n",
       " 'Monroe',\n",
       " 'Nassau',\n",
       " 'Okaloosa',\n",
       " 'Okeechobee',\n",
       " 'Orange',\n",
       " 'Osceola',\n",
       " 'Palm Beach',\n",
       " 'Pasco',\n",
       " 'Pinellas',\n",
       " 'Polk',\n",
       " 'Putnam',\n",
       " 'St. Johns',\n",
       " 'St. Lucie',\n",
       " 'Santa Rosa',\n",
       " 'Sarasota',\n",
       " 'Seminole',\n",
       " 'Sumter',\n",
       " 'Suwannee',\n",
       " 'Taylor',\n",
       " 'Union',\n",
       " 'Volusia',\n",
       " 'Wakulla',\n",
       " 'Walton',\n",
       " 'Washington',\n",
       " 'Appling',\n",
       " 'Atkinson',\n",
       " 'Bacon',\n",
       " 'Baker',\n",
       " 'Baldwin',\n",
       " 'Banks',\n",
       " 'Barrow',\n",
       " 'Bartow',\n",
       " 'Ben Hill',\n",
       " 'Berrien',\n",
       " 'Bibb',\n",
       " 'Bleckley',\n",
       " 'Brantley',\n",
       " 'Brooks',\n",
       " 'Bryan',\n",
       " 'Bulloch',\n",
       " 'Burke',\n",
       " 'Butts',\n",
       " 'Calhoun',\n",
       " 'Camden',\n",
       " 'Candler',\n",
       " 'Carroll',\n",
       " 'Catoosa',\n",
       " 'Charlton',\n",
       " 'Chatham',\n",
       " 'Chattahoochee',\n",
       " 'Chattooga',\n",
       " 'Cherokee',\n",
       " 'Clarke',\n",
       " 'Clay',\n",
       " 'Clayton',\n",
       " 'Clinch',\n",
       " 'Cobb',\n",
       " 'Coffee',\n",
       " 'Colquitt',\n",
       " 'Columbia',\n",
       " 'Cook',\n",
       " 'Coweta',\n",
       " 'Crawford',\n",
       " 'Crisp',\n",
       " 'Dade',\n",
       " 'Dawson',\n",
       " 'Decatur',\n",
       " 'DeKalb',\n",
       " 'Dodge',\n",
       " 'Dooly',\n",
       " 'Dougherty',\n",
       " 'Douglas',\n",
       " 'Early',\n",
       " 'Echols',\n",
       " 'Effingham',\n",
       " 'Elbert',\n",
       " 'Emanuel',\n",
       " 'Evans',\n",
       " 'Fannin',\n",
       " 'Fayette',\n",
       " 'Floyd',\n",
       " 'Forsyth',\n",
       " 'Franklin',\n",
       " 'Fulton',\n",
       " 'Gilmer',\n",
       " 'Glascock',\n",
       " 'Glynn',\n",
       " 'Gordon',\n",
       " 'Grady',\n",
       " 'Greene',\n",
       " 'Gwinnett',\n",
       " 'Habersham',\n",
       " 'Hall',\n",
       " 'Hancock',\n",
       " 'Haralson',\n",
       " 'Harris',\n",
       " 'Hart',\n",
       " 'Heard',\n",
       " 'Henry',\n",
       " 'Houston',\n",
       " 'Irwin',\n",
       " 'Jackson',\n",
       " 'Jasper',\n",
       " 'Jeff Davis',\n",
       " 'Jefferson',\n",
       " 'Jenkins',\n",
       " 'Johnson',\n",
       " 'Jones',\n",
       " 'Lamar',\n",
       " 'Lanier',\n",
       " 'Laurens',\n",
       " 'Lee',\n",
       " 'Liberty',\n",
       " 'Lincoln',\n",
       " 'Long',\n",
       " 'Lowndes',\n",
       " 'Lumpkin',\n",
       " 'McDuffie',\n",
       " 'McIntosh',\n",
       " 'Macon',\n",
       " 'Madison',\n",
       " 'Marion',\n",
       " 'Meriwether',\n",
       " 'Miller',\n",
       " 'Mitchell',\n",
       " 'Monroe',\n",
       " 'Montgomery',\n",
       " 'Morgan',\n",
       " 'Murray',\n",
       " 'Muscogee',\n",
       " 'Newton',\n",
       " 'Oconee',\n",
       " 'Oglethorpe',\n",
       " 'Paulding',\n",
       " 'Peach',\n",
       " 'Pickens',\n",
       " 'Pierce',\n",
       " 'Pike',\n",
       " 'Polk',\n",
       " 'Pulaski',\n",
       " 'Putnam',\n",
       " 'Quitman',\n",
       " 'Rabun',\n",
       " 'Randolph',\n",
       " 'Richmond',\n",
       " 'Rockdale',\n",
       " 'Schley',\n",
       " 'Screven',\n",
       " 'Seminole',\n",
       " 'Spalding',\n",
       " 'Stephens',\n",
       " 'Stewart',\n",
       " 'Sumter',\n",
       " 'Talbot',\n",
       " 'Taliaferro',\n",
       " 'Tattnall',\n",
       " 'Taylor',\n",
       " 'Telfair',\n",
       " 'Terrell',\n",
       " 'Thomas',\n",
       " 'Tift',\n",
       " 'Toombs',\n",
       " 'Towns',\n",
       " 'Treutlen',\n",
       " 'Troup',\n",
       " 'Turner',\n",
       " 'Twiggs',\n",
       " 'Union',\n",
       " 'Upson',\n",
       " 'Walker',\n",
       " 'Walton',\n",
       " 'Ware',\n",
       " 'Warren',\n",
       " 'Washington',\n",
       " 'Wayne',\n",
       " 'Webster',\n",
       " 'Wheeler',\n",
       " 'White',\n",
       " 'Whitfield',\n",
       " 'Wilcox',\n",
       " 'Wilkes',\n",
       " 'Wilkinson',\n",
       " 'Worth',\n",
       " 'Hawaii',\n",
       " 'Honolulu',\n",
       " 'Kalawao',\n",
       " 'Kauai',\n",
       " 'Maui',\n",
       " 'Ada',\n",
       " 'Adams',\n",
       " 'Bannock',\n",
       " 'Bear Lake',\n",
       " 'Benewah',\n",
       " 'Bingham',\n",
       " 'Blaine',\n",
       " 'Boise',\n",
       " 'Bonner',\n",
       " 'Bonneville',\n",
       " 'Boundary',\n",
       " 'Butte',\n",
       " 'Camas',\n",
       " 'Canyon',\n",
       " 'Caribou',\n",
       " 'Cassia',\n",
       " 'Clark',\n",
       " 'Clearwater',\n",
       " 'Custer',\n",
       " 'Elmore',\n",
       " 'Franklin',\n",
       " 'Fremont',\n",
       " 'Gem',\n",
       " 'Gooding',\n",
       " 'Idaho',\n",
       " 'Jefferson',\n",
       " 'Jerome',\n",
       " 'Kootenai',\n",
       " 'Latah',\n",
       " 'Lemhi',\n",
       " 'Lewis',\n",
       " 'Lincoln',\n",
       " 'Madison',\n",
       " 'Minidoka',\n",
       " 'Nez Perce',\n",
       " 'Oneida',\n",
       " 'Owyhee',\n",
       " 'Payette',\n",
       " 'Power',\n",
       " 'Shoshone',\n",
       " 'Teton',\n",
       " 'Twin Falls',\n",
       " 'Valley',\n",
       " 'Washington',\n",
       " 'Adams',\n",
       " 'Alexander',\n",
       " 'Bond',\n",
       " 'Boone',\n",
       " 'Brown',\n",
       " 'Bureau',\n",
       " 'Calhoun',\n",
       " 'Carroll',\n",
       " 'Cass',\n",
       " 'Champaign',\n",
       " 'Christian',\n",
       " 'Clark',\n",
       " 'Clay',\n",
       " 'Clinton',\n",
       " 'Coles',\n",
       " 'Cook',\n",
       " 'Crawford',\n",
       " 'Cumberland',\n",
       " 'DeKalb',\n",
       " 'De Witt',\n",
       " 'Douglas',\n",
       " 'DuPage',\n",
       " 'Edgar',\n",
       " 'Edwards',\n",
       " 'Effingham',\n",
       " 'Fayette',\n",
       " 'Ford',\n",
       " 'Franklin',\n",
       " 'Fulton',\n",
       " 'Gallatin',\n",
       " 'Greene',\n",
       " 'Grundy',\n",
       " 'Hamilton',\n",
       " 'Hancock',\n",
       " 'Hardin',\n",
       " 'Henderson',\n",
       " 'Henry',\n",
       " 'Iroquois',\n",
       " 'Jackson',\n",
       " 'Jasper',\n",
       " 'Jefferson',\n",
       " 'Jersey',\n",
       " 'Jo Daviess',\n",
       " 'Johnson',\n",
       " 'Kane',\n",
       " 'Kankakee',\n",
       " 'Kendall',\n",
       " 'Knox',\n",
       " 'Lake',\n",
       " 'LaSalle',\n",
       " 'Lawrence',\n",
       " 'Lee',\n",
       " 'Livingston',\n",
       " 'Logan',\n",
       " 'McDonough',\n",
       " 'McHenry',\n",
       " 'McLean',\n",
       " 'Macon',\n",
       " 'Macoupin',\n",
       " 'Madison',\n",
       " 'Marion',\n",
       " 'Marshall',\n",
       " 'Mason',\n",
       " 'Massac',\n",
       " 'Menard',\n",
       " 'Mercer',\n",
       " 'Monroe',\n",
       " 'Montgomery',\n",
       " 'Morgan',\n",
       " 'Moultrie',\n",
       " 'Ogle',\n",
       " 'Peoria',\n",
       " 'Perry',\n",
       " 'Piatt',\n",
       " 'Pike',\n",
       " 'Pope',\n",
       " 'Pulaski',\n",
       " 'Putnam',\n",
       " 'Randolph',\n",
       " 'Richland',\n",
       " 'Rock Island',\n",
       " 'St. Clair',\n",
       " 'Saline',\n",
       " 'Sangamon',\n",
       " 'Schuyler',\n",
       " 'Scott',\n",
       " 'Shelby',\n",
       " 'Stark',\n",
       " 'Stephenson',\n",
       " 'Tazewell',\n",
       " 'Union',\n",
       " 'Vermilion',\n",
       " 'Wabash',\n",
       " 'Warren',\n",
       " 'Washington',\n",
       " 'Wayne',\n",
       " 'White',\n",
       " 'Whiteside',\n",
       " 'Will',\n",
       " 'Williamson',\n",
       " 'Winnebago',\n",
       " 'Woodford',\n",
       " 'Beverly',\n",
       " 'Burton',\n",
       " 'Camp Point',\n",
       " 'Clayton',\n",
       " 'Columbus',\n",
       " 'Concord',\n",
       " 'Ellington',\n",
       " 'Fall Creek',\n",
       " 'Gilmer',\n",
       " 'Honey Creek',\n",
       " 'Houston',\n",
       " 'Keene',\n",
       " 'Liberty',\n",
       " 'Lima',\n",
       " 'McKee',\n",
       " 'Melrose',\n",
       " 'Mendon',\n",
       " 'Northeast',\n",
       " 'Payson',\n",
       " 'Quincy',\n",
       " 'Richfield',\n",
       " 'Riverside',\n",
       " 'Ursa',\n",
       " 'Burgess',\n",
       " 'Central',\n",
       " 'Lagrange',\n",
       " 'Mills',\n",
       " 'Mulberry Grove',\n",
       " 'Old Ripley',\n",
       " 'Pleasant Mound',\n",
       " 'Shoal Creek',\n",
       " 'Tamalco',\n",
       " 'Belvidere',\n",
       " 'Bonus',\n",
       " 'Boone',\n",
       " 'Caledonia',\n",
       " 'Flora',\n",
       " 'LeRoy',\n",
       " 'Manchester',\n",
       " 'Poplar Grove',\n",
       " 'Spring',\n",
       " 'Buckhorn',\n",
       " 'Cooperstown',\n",
       " 'Elkhorn',\n",
       " 'Lee',\n",
       " 'Missouri',\n",
       " 'Mount Sterling',\n",
       " 'Pea Ridge',\n",
       " 'Ripley',\n",
       " 'Versailles',\n",
       " 'Arispie',\n",
       " 'Berlin',\n",
       " 'Bureau',\n",
       " 'Clarion',\n",
       " 'Concord',\n",
       " 'Dover',\n",
       " 'Fairfield',\n",
       " 'Gold',\n",
       " 'Greenville',\n",
       " 'Hall',\n",
       " 'Indiantown',\n",
       " 'La Moille',\n",
       " 'Leepertown',\n",
       " 'Macon',\n",
       " 'Manlius',\n",
       " 'Milo',\n",
       " 'Mineral',\n",
       " 'Neponset',\n",
       " 'Ohio',\n",
       " 'Princeton',\n",
       " 'Selby',\n",
       " 'Walnut',\n",
       " 'Westfield',\n",
       " 'Wheatland',\n",
       " 'Wyanet',\n",
       " 'Cherry Grove-Shannon',\n",
       " 'Elkhorn Grove',\n",
       " 'Fairhaven',\n",
       " 'Freedom',\n",
       " 'Mount Carroll',\n",
       " 'Rock Creek-Lima',\n",
       " 'Salem',\n",
       " 'Savanna',\n",
       " 'Washington',\n",
       " 'Woodland',\n",
       " 'Wysox',\n",
       " 'York',\n",
       " 'Arenzville',\n",
       " 'Ashland',\n",
       " 'Beardstown',\n",
       " 'Bluff Springs',\n",
       " 'Chandlerville',\n",
       " 'Hagener',\n",
       " 'Newmansville',\n",
       " 'Panther Creek',\n",
       " 'Philadelphia',\n",
       " 'Sangamon Valley',\n",
       " 'Virginia',\n",
       " 'Ayers',\n",
       " 'Brown',\n",
       " 'Champaign',\n",
       " 'Champaign City',\n",
       " 'Colfax',\n",
       " 'Compromise',\n",
       " 'Condit',\n",
       " 'Crittenden',\n",
       " 'Cunningham',\n",
       " 'East Bend',\n",
       " 'Harwood',\n",
       " 'Hensley',\n",
       " 'Kerr',\n",
       " 'Ludlow',\n",
       " 'Mahomet',\n",
       " 'Newcomb',\n",
       " 'Ogden',\n",
       " 'Pesotum',\n",
       " 'Philo',\n",
       " 'Rantoul',\n",
       " 'Raymond',\n",
       " 'Sadorus',\n",
       " 'St. Joseph',\n",
       " 'Scott',\n",
       " 'Sidney',\n",
       " 'Somer',\n",
       " 'South Homer',\n",
       " 'Stanton',\n",
       " 'Tolono',\n",
       " 'Urbana',\n",
       " 'Assumption',\n",
       " 'Bear Creek',\n",
       " 'Buckhart',\n",
       " 'Greenwood',\n",
       " 'Johnson',\n",
       " ...]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(geo[\"Area Name (including legal/statistical area description)\"])\n",
    "#a1 = a[0].split()\n",
    "\n",
    "#a1[0:(len(a1)-1)]\n",
    "\n",
    "city_list = list()\n",
    "for i in range(len(a)):\n",
    "    a1 = a[i].split()\n",
    "    a1 = a1[0:(len(a1)-1)]\n",
    "    a2 = \" \".join(a1)\n",
    "    city_list.append(a2)\n",
    "city_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "86d0bae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24283"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        #name을 공백을 기준으로 분리후 집합으로 선언합니다.\n",
    "        #n1std = set(name_std[id1].split())\n",
    "        #n2std = set(name_std[id2].split())\n",
    "        \n",
    "        #생성된 집합끼리 차집합 연산을 통해 공통된 원소를 삭제하고 다시 리스트로 변환합니다.\n",
    "        #n1std1 = list(n1std - n2std)\n",
    "        #n2std2 = list(n2std - n1std)\n",
    "        \n",
    "        #공통 원소가 제거된 원소를 다시 문자열로 복원시킵니다.\n",
    "        #n1std = \" \".join(n1std1)\n",
    "        #n2std = \" \".join(n2std2)\n",
    "len(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0346561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24283"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7dd656e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "geo.to_csv(\"/mnt/user2/R/geo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e366c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventor = pd.read_csv(\"/mnt/user2/R/all_inventors.csv\") #dtype={\"State Code (FIPS)\" : str, \"County Code (FIPS)\" : str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6723672",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_inventor = inventor[inventor[\"inventor_country_code\"] == \"US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "45daa9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_inventor.to_csv(\"/mnt/user2/R/us_inventor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "be94203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatch = pd.read_csv(\"/mnt/user2/R/unmatch.csv\")\n",
    "fips = pd.read_csv(\"/mnt/user2/R/FIPS.csv\")\n",
    "fips_making = pd.read_csv(\"/mnt/user2/R/fips_making.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a4fe2684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>inventor_name_first</th>\n",
       "      <th>inventor_name_middle</th>\n",
       "      <th>inventor_name_last</th>\n",
       "      <th>inventor_rank</th>\n",
       "      <th>inventor_city_name</th>\n",
       "      <th>inventor_region_code</th>\n",
       "      <th>FIPS.x</th>\n",
       "      <th>State Code (FIPS)</th>\n",
       "      <th>FIPS.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10015986</td>\n",
       "      <td>Kristina</td>\n",
       "      <td>J.</td>\n",
       "      <td>Hennessy</td>\n",
       "      <td>1</td>\n",
       "      <td>parkville</td>\n",
       "      <td>MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10015986</td>\n",
       "      <td>Karen</td>\n",
       "      <td>K.</td>\n",
       "      <td>Brown</td>\n",
       "      <td>2</td>\n",
       "      <td>parkville</td>\n",
       "      <td>MO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10048355</td>\n",
       "      <td>David</td>\n",
       "      <td>P</td>\n",
       "      <td>Chastain</td>\n",
       "      <td>1</td>\n",
       "      <td>action</td>\n",
       "      <td>MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10089942</td>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chesnut</td>\n",
       "      <td>5</td>\n",
       "      <td>cardiff-by-the-sea</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10207755</td>\n",
       "      <td>Robert</td>\n",
       "      <td>L.</td>\n",
       "      <td>Studer</td>\n",
       "      <td>2</td>\n",
       "      <td>lake alice rose</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867778</th>\n",
       "      <td>90019010</td>\n",
       "      <td>DELPHI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TECHNOLOGIES INC (PATENT OWNER)</td>\n",
       "      <td>2</td>\n",
       "      <td>annadale</td>\n",
       "      <td>VA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867779</th>\n",
       "      <td>90019010</td>\n",
       "      <td>BMW OF NORTH AMERICA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LLC (3RD PTY. REQ.)</td>\n",
       "      <td>3</td>\n",
       "      <td>woodcliff lake,</td>\n",
       "      <td>NJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867780</th>\n",
       "      <td>90014650</td>\n",
       "      <td>ARJUNA NATURAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PRIVATE LIMITED (PATENT OWNER)</td>\n",
       "      <td>2</td>\n",
       "      <td>alwaye</td>\n",
       "      <td>IN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867781</th>\n",
       "      <td>17274116</td>\n",
       "      <td>Murali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NARASIMHA</td>\n",
       "      <td>1</td>\n",
       "      <td>lake osweg</td>\n",
       "      <td>OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867782</th>\n",
       "      <td>17216485</td>\n",
       "      <td>John</td>\n",
       "      <td>P.</td>\n",
       "      <td>Ternus</td>\n",
       "      <td>6</td>\n",
       "      <td>los altos hills</td>\n",
       "      <td>CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>867783 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_number   inventor_name_first inventor_name_middle  \\\n",
       "0                10015986              Kristina                   J.   \n",
       "1                10015986                 Karen                   K.   \n",
       "2                10048355                 David                    P   \n",
       "3                10089942                Robert                  NaN   \n",
       "4                10207755                Robert                   L.   \n",
       "...                   ...                   ...                  ...   \n",
       "867778           90019010                DELPHI                  NaN   \n",
       "867779           90019010  BMW OF NORTH AMERICA                  NaN   \n",
       "867780           90014650        ARJUNA NATURAL                  NaN   \n",
       "867781           17274116                Murali                  NaN   \n",
       "867782           17216485                  John                   P.   \n",
       "\n",
       "                     inventor_name_last  inventor_rank  inventor_city_name  \\\n",
       "0                              Hennessy              1           parkville   \n",
       "1                                 Brown              2           parkville   \n",
       "2                              Chastain              1              action   \n",
       "3                               Chesnut              5  cardiff-by-the-sea   \n",
       "4                                Studer              2     lake alice rose   \n",
       "...                                 ...            ...                 ...   \n",
       "867778  TECHNOLOGIES INC (PATENT OWNER)              2            annadale   \n",
       "867779              LLC (3RD PTY. REQ.)              3     woodcliff lake,   \n",
       "867780   PRIVATE LIMITED (PATENT OWNER)              2              alwaye   \n",
       "867781                        NARASIMHA              1          lake osweg   \n",
       "867782                           Ternus              6     los altos hills   \n",
       "\n",
       "       inventor_region_code  FIPS.x  State Code (FIPS)  FIPS.y  \n",
       "0                        MO     NaN                NaN     NaN  \n",
       "1                        MO     NaN                NaN     NaN  \n",
       "2                        MA     NaN                NaN     NaN  \n",
       "3                        CA     NaN                NaN     NaN  \n",
       "4                        WA     NaN                NaN     NaN  \n",
       "...                     ...     ...                ...     ...  \n",
       "867778                   VA     NaN                NaN     NaN  \n",
       "867779                   NJ     NaN                NaN     NaN  \n",
       "867780                   IN     NaN                NaN     NaN  \n",
       "867781                   OR     NaN                NaN     NaN  \n",
       "867782                   CA     NaN                NaN     NaN  \n",
       "\n",
       "[867783 rows x 10 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def matching_machine(a, b):\n",
    "    unmatch[\"invertor_city_name\", \"inventor_region_code\"][\"inventor_region_code\" == a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aa274b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33333333333333337"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leven.get_sim_score(\"aa\", \"abc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sw",
   "language": "python",
   "name": "sw"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
